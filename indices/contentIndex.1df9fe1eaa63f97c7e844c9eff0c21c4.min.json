{"/":{"title":"Home","content":"\nğŸ•µï¸â€â™‚ï¸ This is Jude Wang's vault about his notebook, his knowledge, his second brain. \n\nğŸš§ There are notebooks about his research career:\n\n* [Deep Learning](Deep%20Learning%20And%20Machine%20Learning/Deep%20_Learning_MOC.md)\n\n* [Signal Processing](Signal%20Processing/Signal%20Processing_MOC.md)\n\n* [[Synthetic Aperture Radar Imaging/SAR_MOC| Synthetic Aperture Radar(SAR) Imaging]]\n\n* [Hardware](Hardware/Hardware_MOC.md)\n\nğŸ›¶ Also, he learn some knowledge about his hobbies:\n\n* [ğŸ“· Photography](Photography/Photography_MOC.md)\n\n* [ğŸ“®æ–‡å­¦](æ–‡å­¦/æ–‡å­¦_MOC.md)\n\n","lastmodified":"2023-03-30T12:42:55.36655479Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/%E5%8F%A5%E5%AD%90":{"title":"å¥å­","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n* [ğŸŒ¸Love about](æ–‡å­¦/å¥å­/Love%20about.md)\n* [ğŸ–‹Poem](æ–‡å­¦/å¥å­/Poem.md)\n* [ğŸ§—ğŸ»â€â™‚ï¸Motivation](æ–‡å­¦/å¥å­/Motivation.md)\n* [ğŸ§¶Feeling](æ–‡å­¦/å¥å­/Feeling.md)\n* [ğŸ Movie](æ–‡å­¦/å¥å­/Movie.md)\n","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Feeling":{"title":"ğŸ§¶Feeling","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e A Sentence\n\u003e \n\u003e ä¸€ä¸ªå¤ªè¿‡äºæ–‡è‰ºçš„äººæ³¨å®šä¸ä¼šå¿«ä¹ï¼Œå› ä¸ºå¿ƒä¸­æœ‰çˆ± æœ‰å–„è‰¯ï¼Œéª¨å­é‡Œä½ç€å­©å­èˆ¬çš„çº¯çœŸï¼Œä½†ä¹Ÿå¾€å¾€å®¹æ˜“å¤šæ„å–„æ„Ÿï¼Œå®¹æ˜“æ„ŸçŸ¥ç¾å¥½ï¼Œä¹Ÿæ›´å®¹æ˜“ä½“ä¼šæ‚²ä¼¤ã€‚å¥¹å–œæ¬¢æ–‡å­—ï¼Œå¾€å¾€ä¸å–„è¨€è¾ï¼Œä¸æ˜¯æ–‡å­—å¤ªå°‘ï¼Œè€Œæ˜¯æ„Ÿå—å¤ªå¤šã€‚\n\u003e  \u003cp style=\"text-align:right\"\u003eâ€”â€”ä¸‰æ¯›\u003c/p\u003e\n  ","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Love-about":{"title":"ğŸŒ¸Love","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n  \u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1V24y1x7Nh/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=4AD8E5F4-D617-499B-9C19-D5897A7EB825\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679378304\u0026unique_k=tXa4xdJ\u0026up_id=315154029\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \u003cbr\u003e\n\u003e â€œè‡³å°‘æœ‰ä¸¤æ¬¡å–œæ¬¢\u003cbr\u003e\n\u003e ä¸€æ¬¡å‘ç”Ÿåœ¨åœ¨ä¸€èµ·ä¹‹å‰ï¼Œä¸€æ¬¡å‘ç”Ÿåœ¨ä¹‹åï¼Œ\u003cbr\u003e\n\u003e ç¬¬ä¸€æ¬¡æ˜¯å–œæ¬¢ä¸Šä½ ã€‚ç¬¬äºŒæ¬¡æ˜¯å–œæ¬¢ä¸Šæˆ‘ä»¬ï¼Œ\u003cbr\u003e\n\u003e æˆ‘åªæ•¢æŠŠç¬¬äºŒæ¬¡ç¿»è¯‘æˆçˆ±ï¼Œ\u003cbr\u003e\n\u003e ç¬¬ä¸€æ¬¡æ˜¯å› ä¸ºä½ å¾ˆå¥½ï¼Œç¬¬äºŒæ¬¡æ˜¯å› ä¸ºæˆ‘è¿˜æ²¡æœ‰ååˆ°æ•¢æ”¾æ»¡æ‰ç¢ä½ çš„å¥½ã€‚\u003cbr\u003e\n\u003e æˆ‘è¦å°å¿ƒçš„æ§ç€ç¬¬ä¸€æ¬¡çš„å–œæ¬¢ï¼Œå°±åƒæå‡ºä¸€ä»½æ‰‹å†™çš„åˆç¨¿ï¼Œ\u003cbr\u003e\n\u003e ä½ ä¼šæ¥è¿‡æˆ‘çš„ç›®å…‰ï¼Œåœ¨å²æœˆé‡Œé‡æ–°èªŠå†™å²æœˆï¼Œ\u003cbr\u003e\n\u003e è¦åˆ æ”¹çš„åœ°æ–¹è¿˜å¾ˆå¤šï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼ŒæŠŠå·®é”™ç¿»è¯‘æˆå¹½é»˜\u003cbr\u003e\n\u003e æ”¹äº†è¿˜æ˜¯å­˜åœ¨å•Šï¼Œçˆ±æƒ…æœ¬å°±æ˜¯å¬èµ·æ¥å¾ˆç¾çš„ï¼Œé˜´å·®é˜³é”™â€\n\n\n--- \n\n\u003e [!quote] \n\u003e A Sentence\n\u003e \n\u003e \"I am too full of life to be half-loved\"\n\u003e \n\n![400](æ–‡å­¦/attachments/Pasted%20image%2020230321142115.png)\n\n---\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1Vd4y187Tq/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=F81E6185-E382-4E78-95FD-3155869F570B\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679380048\u0026unique_k=Q9GSCLM\u0026up_id=2009238634\u0026vd_source=c47136abc78922800b17d6ce79d6e19f)\u003cbr\u003e\n\u003e  â€œä»–å¬çš„å°ä¼—éŸ³ä¹ï¼Œ\u003cbr\u003e\n\u003e  ç¬¬äºŒå¤©ä¸Šäº†æŠ–éŸ³çƒ­æ¦œã€‚\u003cbr\u003e\n\u003e  ä»–çˆ±åƒçš„è‹è‡å°é¦†ï¼Œ\u003cbr\u003e\n\u003e  ç¬¬äºŒå¤©å…¨å›½è¿é”äº†ä¸€ä¸‡å®¶ã€‚\u003cbr\u003e\n\u003e  ä»–çˆ±çš„å¿åŸå§‘å¨˜ï¼Œ\u003cbr\u003e\n\u003e  ç¬¬äºŒå¤©å‡ºå›½ç•™å­¦å†ä¹Ÿæ²¡å›æ¥ã€‚\u003cbr\u003e\n\u003e  ä»–è§‰å¾—é‚£äº›ç‰¹åˆ«ï¼Œ\u003cbr\u003e\n\u003e  éƒ½å·²çƒŸæ¶ˆäº‘æ•£ï¼Œ\u003cbr\u003e\n\u003e  å¯é‚£äº›ç‰¹åˆ«ä¸€ç›´éƒ½åœ¨ï¼Œ\u003cbr\u003e\n\u003e  é”™å°±é”™åœ¨ä»–è®¤ä¸ºç‰¹åˆ«\u003cbr\u003e\n\u003e  åªå±äºä»–ã€‚â€\u003cbr\u003e\n\u003e  \u003ca href=\"https://space.bilibili.com/2009238634\"\u003e\u003cp style=\"text-align:right\"\u003eâ€”â€”ç¥ºç™½çŸ³\u003c/p\u003e\u003c/a\u003e\n\n![400](æ–‡å­¦/attachments/Pasted%20image%2020230321143300.png)","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Motivation":{"title":"ğŸ§—ğŸ»â€â™‚ï¸Motivation","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n  \u003c/script\u003e\n\u003e [!quote] \n\u003e A Sentence\n\u003e \n\u003e \"No easy basket\"\n\nâ€œå¦‚æœä½ æƒ³äº†è§£Americanç¯®çƒçš„æ ¹åŸºï¼Œä½ è¦å»çœ‹çœ‹ç¾é«˜â€\n","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Movie":{"title":"From Movie","content":"\n\u003e [!quote] \n\u003e  é“ƒèŠ½ä¹‹æ—…\n\u003e  \n\u003e  \"é®ä½åœŸåœ°çš„æ˜¯äººå¿ƒçš„é‡é‡ã€‚\"\n\n","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Novel":{"title":"From Novel","content":"\n\u003e [!quote] \n\u003e From CC98, credits to someone\n\u003e \n\u003e å¾ˆå¥‡æ€ªï¼Œä¸ä¸€ä¸ªäººå‘Šåˆ«ä¹‹åç”·ç”Ÿè®°èµ·æ¥çš„æ°¸è¿œæ˜¯ä¸€äº›å¾®ä¸è¶³é“çš„ç»†èŠ‚ï¼Œç”·ç”Ÿä¸çŸ¥é“å¥³ç”Ÿçš„åå­—ï¼Œä¹Ÿä¸è®°å¾—å¥³ç”Ÿå¸¸ç©¿çš„è¡£æœæ˜¯ä»€ä¹ˆé¢œè‰²ï¼Œç”·ç”Ÿå¿˜æ‰äº†æ¯å¤©åœ¨æ¡¥è¾¹ä¸Šç­‰å¥³ç”Ÿçš„æ—¶é—´ï¼Œå¥³ç”Ÿçš„çœ¼ç›ä¹Ÿæ…¢æ…¢åœ¨ç”·ç”Ÿçš„è®°å¿†é‡Œè’™å°˜ã€‚ \n\u003e \n\u003e ä¸è¿‡ç”·ç”Ÿè®°å¾—ç­‰å¥³ç”Ÿæ—¶æ¡¥ä¸‹çš„æµæ°´æ½ºæ½ºï¼Œä¹Ÿè®°å¾—æ ¡å›­é‡ŒæŸä¸ªè§’è½ä»–ä»¬ç»å¸¸å»çœ‹çš„å››å¶è‰ï¼Œè®°å¾—ç¬¬ä¸€æ¬¡æ³¨æ„åˆ°å¥³ç”Ÿæ—¶å…¬äº¤ç«™é¡¶ä¸Šé‚£ç‰‡ä¸åŒçš„è½å¶ï¼Œä¹Ÿè®°å¾—æ­¥é“æ—å¥³ç”ŸæŒ‡ç»™ä»–çœ‹çš„æ ‘çš®ã€‚ \n\u003e \n\u003e åæ¥ç”·ç”Ÿçœ‹äº†é˜¿å°”ç“¦é›·æ–¯çš„ã€Šè¡Œèµ°çš„è·ç¦»ã€‹ï¼Œé‡Œé¢æœ‰å¥è¯æ˜¯â€œåˆ«äººç¨ä¸€æ³¨æ„ä½ ï¼Œä½ å°±æ•å¼€å¿ƒæ‰‰ï¼Œä½ è§‰å¾—è¿™æ˜¯å¦ç‡ï¼Œå…¶å®è¿™æ˜¯å­¤ç‹¬ã€‚â€\n\u003e \n\u003e  ç”·ç”Ÿä¸çŸ¥é“è‡ªå·±æ˜¯ä¸æ˜¯å­¤ç‹¬ï¼Œä¹Ÿä¸çŸ¥é“è‡ªå·±æ˜¯ä¸æ˜¯å¦ç‡ã€‚ç”·ç”Ÿä¸å…³å¿ƒã€‚ \n\u003e  \n\u003e  ç”·ç”Ÿå¾ˆæ„Ÿè°¢é‚£ä¸ªå¥³ç”Ÿã€‚ \n\u003e  \n\u003e  ç”·ç”Ÿå¾ˆæƒ³å†™ä¸‹â€œä¸è¿‡ç”·ç”Ÿå¹¶ä¸æƒ³å¿µé‚£ä¸ªå¥³ç”Ÿâ€ã€‚ \n\u003e  \n\u003e  ä¸è¿‡ç”·ç”Ÿå¾ˆæƒ³å¿µé‚£ä¸ªå¥³ç”Ÿã€‚\n","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E5%8F%A5%E5%AD%90/Poem":{"title":"ğŸ–‹Poem","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1V24y1x7Nh/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=4AD8E5F4-D617-499B-9C19-D5897A7EB825\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679378304\u0026unique_k=tXa4xdJ\u0026up_id=315154029\u0026vd_source=c47136abc78922800b17d6ce79d6e19f) \u003cbr\u003e\n\u003e â€œè‡³å°‘æœ‰ä¸¤æ¬¡å–œæ¬¢\u003cbr\u003e\n\u003e ä¸€æ¬¡å‘ç”Ÿåœ¨åœ¨ä¸€èµ·ä¹‹å‰ï¼Œä¸€æ¬¡å‘ç”Ÿåœ¨ä¹‹åï¼Œ\u003cbr\u003e\n\u003e ç¬¬ä¸€æ¬¡æ˜¯å–œæ¬¢ä¸Šä½ ã€‚ç¬¬äºŒæ¬¡æ˜¯å–œæ¬¢ä¸Šæˆ‘ä»¬ï¼Œ\u003cbr\u003e\n\u003e æˆ‘åªæ•¢æŠŠç¬¬äºŒæ¬¡ç¿»è¯‘æˆçˆ±ï¼Œ\u003cbr\u003e\n\u003e ç¬¬ä¸€æ¬¡æ˜¯å› ä¸ºä½ å¾ˆå¥½ï¼Œç¬¬äºŒæ¬¡æ˜¯å› ä¸ºæˆ‘è¿˜æ²¡æœ‰ååˆ°æ•¢æ”¾æ»¡æ‰ç¢ä½ çš„å¥½ã€‚\u003cbr\u003e\n\u003e æˆ‘è¦å°å¿ƒçš„æ§ç€ç¬¬ä¸€æ¬¡çš„å–œæ¬¢ï¼Œå°±åƒæå‡ºä¸€ä»½æ‰‹å†™çš„åˆç¨¿ï¼Œ\u003cbr\u003e\n\u003e ä½ ä¼šæ¥è¿‡æˆ‘çš„ç›®å…‰ï¼Œåœ¨å²æœˆé‡Œé‡æ–°èªŠå†™å²æœˆï¼Œ\u003cbr\u003e\n\u003e è¦åˆ æ”¹çš„åœ°æ–¹è¿˜å¾ˆå¤šï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼ŒæŠŠå·®é”™ç¿»è¯‘æˆå¹½é»˜\u003cbr\u003e\n\u003e æ”¹äº†è¿˜æ˜¯å­˜åœ¨å•Šï¼Œçˆ±æƒ…æœ¬å°±æ˜¯å¬èµ·æ¥å¾ˆç¾çš„ï¼Œé˜´å·®é˜³é”™â€\n\n---\n\n\u003e [!quote] \n\u003e [A poem](https://www.bilibili.com/video/BV1Vd4y187Tq/?buvid=YF4AFCFA7E0887094E329B9A6FADF98BF343\u0026is_story_h5=false\u0026mid=B1quk6Mlu6tnRY8zjwxWeg%3D%3D\u0026p=1\u0026plat_id=116\u0026share_from=ugc\u0026share_medium=iphone\u0026share_plat=ios\u0026share_session_id=F81E6185-E382-4E78-95FD-3155869F570B\u0026share_source=QQ\u0026share_tag=s_i\u0026timestamp=1679380048\u0026unique_k=Q9GSCLM\u0026up_id=2009238634\u0026vd_source=c47136abc78922800b17d6ce79d6e19f)\u003cbr\u003e\n\u003e  â€œä»–å¬çš„å°ä¼—éŸ³ä¹ï¼Œ\u003cbr\u003e\n\u003e  ç¬¬äºŒå¤©ä¸Šäº†æŠ–éŸ³çƒ­æ¦œã€‚\u003cbr\u003e\n\u003e  ä»–çˆ±åƒçš„è‹è‡å°é¦†ï¼Œ\u003cbr\u003e\n\u003e  ç¬¬äºŒå¤©å…¨å›½è¿é”äº†ä¸€ä¸‡å®¶ã€‚\u003cbr\u003e\n\u003e  ä»–çˆ±çš„å¿åŸå§‘å¨˜ï¼Œ\u003cbr\u003e\n\u003e  ç¬¬äºŒå¤©å‡ºå›½ç•™å­¦å†ä¹Ÿæ²¡å›æ¥ã€‚\u003cbr\u003e\n\u003e  ä»–è§‰å¾—é‚£äº›ç‰¹åˆ«ï¼Œ\u003cbr\u003e\n\u003e  éƒ½å·²çƒŸæ¶ˆäº‘æ•£ï¼Œ\u003cbr\u003e\n\u003e  å¯é‚£äº›ç‰¹åˆ«ä¸€ç›´éƒ½åœ¨ï¼Œ\u003cbr\u003e\n\u003e  é”™å°±é”™åœ¨ä»–è®¤ä¸ºç‰¹åˆ«\u003cbr\u003e\n\u003e  åªå±äºä»–ã€‚â€\u003cbr\u003e\n\u003e  \u003ca href=\"https://space.bilibili.com/2009238634\"\u003e\u003cp style=\"text-align:right\"\u003eâ€”â€”ç¥ºç™½çŸ³\u003c/p\u003e\u003c/a\u003e\n\n![400](æ–‡å­¦/attachments/Pasted%20image%2020230321143300.png)","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/%E6%96%87%E5%AD%A6_MOC":{"title":"æ–‡å­¦","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n\nIn this MOC, it shows you the path to what I record for some interesting sentences, including Chinese and English, even Japanese.\n\n[ğŸŒŒå¥å­](æ–‡å­¦/å¥å­/å¥å­.md)\n\n[ğŸ“œåŸåˆ›è¯—](æ–‡å­¦/Poem_by_me.md)\n","lastmodified":"2023-03-30T12:42:55.374554923Z","tags":null},"/%E6%96%87%E5%AD%A6/Poem_by_me":{"title":"My Poem","content":"\n  \u003cstyle\u003e\n    p {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n\n    a {\n        font-family: Source Sans Pro, SimSun;\n        font-variant-east-asian: traditional;\n    }\n  \u003c/style\u003e\n","lastmodified":"2023-03-30T12:42:55.36655479Z","tags":null},"/.trash/attachments/Pasted-image-20230320150424.png":{"title":"Pasted image 20230320150424.png","content":"","lastmodified":"2023-03-30T12:42:55.278553332Z","tags":null},"/Circuit/Basic/Electric_units":{"title":"Electric Units","content":"# Electrical impedance\n\n$$\nZ = \\sqrt{R^2 + {(X_L-X_C)}^2}\n$$\n\n\n* $Z$ = impedance\n* $R$ = resistance\n* $X_L$  = inductive reactance\n* $X_C$  = capacitive reactance\n\n![](Circuit/Basic/attachments/Pasted%20image%2020230330163734.png)\n\n**é˜»æŠ—**æ˜¯ç”µè·¯ä¸­ç”µé˜»ã€ç”µæ„Ÿã€ç”µå®¹å¯¹äº¤æµç”µçš„é˜»ç¢ä½œç”¨çš„ç»Ÿç§°ã€‚é˜»æŠ—æ˜¯ä¸€ä¸ªå¤æ•°ï¼Œå®éƒ¨ç§°ä¸º**ç”µé˜»**ï¼Œè™šéƒ¨ç§°ä¸º**ç”µæŠ—**ï¼›å…¶ä¸­ç”µå®¹åœ¨ç”µè·¯ä¸­å¯¹äº¤æµç”µæ‰€èµ·çš„é˜»ç¢ä½œç”¨ç§°ä¸º**å®¹æŠ—**ï¼Œç”µæ„Ÿåœ¨ç”µè·¯ä¸­å¯¹äº¤æµç”µæ‰€èµ·çš„é˜»ç¢ä½œç”¨ç§°ä¸º**æ„ŸæŠ—**ï¼Œå®¹æŠ—å’Œæ„ŸæŠ—åˆç§°ä¸º**ç”µæŠ—**ã€‚\n\né˜»æŠ—å°†ç”µé˜»çš„æ¦‚å¿µåŠ ä»¥å»¶ä¼¸è‡³äº¤æµç”µè·¯é¢†åŸŸï¼Œä¸ä»…æè¿°*ç”µå‹ä¸ç”µæµçš„ç›¸å¯¹æŒ¯å¹…*ï¼Œä¹Ÿæè¿°å…¶*ç›¸å¯¹ç›¸ä½*ã€‚å½“é€šè¿‡ç”µè·¯çš„ç”µæµæ˜¯ç›´æµç”µæ—¶ï¼Œç”µé˜»ä¸é˜»æŠ—ç›¸ç­‰ï¼Œç”µé˜»å¯ä»¥è§†ä¸ºç›¸ä½ä¸ºé›¶çš„é˜»æŠ—ã€‚\n\n## å½¢å¼\n\n1. $R+jX$\n2. $Z_m\\angle\\theta$\n3. $Z_m e^{j\\theta}$\n\né˜»æŠ—å®šä¹‰ä¸ºç”µå‹ä¸ç”µæµçš„é¢‘åŸŸæ¯”ç‡ã€‚é˜»æŠ—çš„å¤§å°$Z_{m}$ æ˜¯ç”µå‹æŒ¯å¹…ä¸ç”µæµæŒ¯å¹…çš„ç»å¯¹å€¼æ¯”ç‡ï¼Œé˜»æŠ—çš„ç›¸ä½ $\\theta$æ˜¯ç”µå‹ä¸ç”µæµçš„ç›¸ä½å·®ã€‚\n\n## æ¬§å§†å®šå¾‹\n\n$$\nv = iZ = iZ_m e^{j\\theta}\n$$\n\né˜»æŠ—å¤§å°$Z_m$çš„ä½œç”¨æ°å·§å°±åƒç”µé˜»ï¼Œè®¾å®šç”µæµ$i$ï¼Œå°±å¯ä»¥è®¡ç®—å‡ºé˜»æŠ—$Z$ä¸¤ç«¯çš„ç”µå‹é™$v$ã€‚ç›¸ä½å› å­$e^{j\\theta}$åˆ™æ˜¯ç”µæµæ»åäºç”µå‹çš„ç›¸ä½å·®$\\theta$ \n\n\u003e [!tip] \n\u003e åœ¨æ—¶åŸŸä¸­ï¼Œç”µæµä¿¡å·ä¼šæ¯”ç”µå‹ä¿¡å·æ…¢$\\theta T/2\\pi$ç§’\n\n## ç†æƒ³çš„é˜»æŠ—\n$$\nZ_R = R\n$$\n\n$$\nZ_C = \\frac{1}{j\\omega C}\n$$\n\n$$\nZ_L = j \\omega L\n$$\n\n* å¯¹äºç”µå®¹ï¼Œäº¤æµç”µå‹æ»å90Â°äºäº¤æµç”µæµï¼›\n* å¯¹äºç”µæ„Ÿï¼Œäº¤æµç”µå‹è¶…å‰90Â°äºäº¤æµç”µæµ\n\n### å®¹æŠ—\n\n$$\nX_C = -j/\\omega C\n$$\néšç€$\\omega$è¶‹å‘äº0ï¼Œç”µæºè¶‹å‘äºç›´æµç”µæºï¼Œå®¹æŠ—çš„ç»å¯¹å€¼è¶‹å‘äºæ— ç©·ï¼›*å› æ­¤ï¼Œåœ¨ä½é¢‘ç‡è¿ä½œæ—¶ï¼Œç”µå®¹å™¨è²Œä¼¼æ–­è·¯ã€‚å‡è®¾ç”µæºçš„é¢‘ç‡è¶Šé«˜ï¼Œåˆ™å®¹æŠ—è¶Šä½ï¼Œå¯¹äºç”µæµé€šè¿‡çš„é˜»ç¢ä¹Ÿè¶Šä½ã€‚åœ¨é«˜é¢‘ç‡è¿ä½œæ—¶ï¼Œç”µå®¹å™¨è²Œä¼¼çŸ­è·¯ã€‚*\n\n### é˜»æŠ—\n\n$$\nX_L = j\\omega L\n$$\nä»è¿™æ–¹ç¨‹å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œå½“äº¤æµç”µæºçš„è§’é¢‘ç‡è¶‹å‘äºé›¶æ—¶ï¼Œç”µæºä¼šè¶‹å‘äºç›´æµç”µæºï¼Œæ„ŸæŠ—ä¼šè¶‹å‘äºé›¶ï¼Œå¯¹äºç”µæµçš„é€šè¿‡é˜»ç¢è¶Šä½ã€‚*æ‰€ä»¥ï¼Œåœ¨ä½é¢‘ç‡è¿ä½œæ—¶ï¼Œç”µæ„Ÿå™¨è²Œä¼¼çŸ­è·¯ã€‚å‡è®¾ç”µæºè§’é¢‘ç‡è¶Šé«˜ï¼Œåˆ™æ„ŸæŠ—è¶Šé«˜ï¼Œå‡è®¾ç»™å®šç”µå‹æºæŒ¯å¹…ï¼Œåˆ™ç”µæµä¼šè¶‹å‘äºé›¶ã€‚æ‰€ä»¥ï¼Œåœ¨é«˜é¢‘ç‡è¿ä½œæ—¶ï¼Œç”µæ„Ÿå™¨è²Œä¼¼æ–­è·¯ã€‚*\n\n\n# Reference\n\n[ç”µæ°”å•ä½ï¼ˆVï¼ŒAï¼ŒÎ©ï¼ŒWï¼Œ...ï¼‰ (rapidtables.org)](https://www.rapidtables.org/zh-CN/electric/Electric_units.html)\n","lastmodified":"2023-03-30T12:42:55.278553332Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep-Learning-Block/Attention":{"title":"â­Attenion","content":"# Self-Attention\n\nè®²è¿°self-attentionæˆ‘ä»¬ä»¥*sequence labeling*ä»»åŠ¡ä½œä¸ºä»»åŠ¡æ¥è®²è§£ï¼Œsequence labelingçš„ä»»åŠ¡æ˜¯è¾“å…¥Nä¸ªvectorå¹¶ä¸”è¾“å‡ºNä¸ªlabelã€‚\n\nå…¸å‹çš„ä¾‹å­æœ‰è¾“å…¥ä¸€ä¸ªå¥å­ï¼Œåˆ†ææ¯ä¸ªè¯æ±‡çš„è¯æ€§æ˜¯ä»€ä¹ˆï¼Œæ¯”å¦‚å¥å­â€œI saw a sawâ€ï¼Œè¿™ä¸ªå¥å­é‡Œsawå’Œsawçš„è¯æ€§åˆ†åˆ«æ˜¯verbå’Œnonuï¼Œå¦‚æœæˆ‘ä»¬ç”¨fully-connectedï¼ˆFCï¼‰å±‚æ¥åšçš„è¯ï¼Œé‚£ä¹ˆé¢å¯¹åŒæ ·çš„è¾“å…¥sawï¼Œæˆ‘ä»¬æ— æ³•å¾—å‡ºä¸åŒçš„ç»“æœã€‚\n\n![Pasted image 20230315195403](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/1.png)\n\næˆ‘ä»¬çš„åšæ³•å¯ä»¥æ˜¯å¯¹è¾“å…¥åŠ çª—ï¼Œè€ƒè™‘å‘¨è¾¹é‚»è¿‘çš„è¯æ±‡ä¿¡æ¯ï¼Œè¿™ä¸ä¿¡å·å¤„ç†å¸¸ç”¨çš„æ–¹æ³•ç±»ä¼¼ï¼Œä½†æ˜¯çª—çš„é•¿åº¦æ˜¯æœ‰é™ä¸”å›ºå®šçš„ï¼Œè€Œseqçš„é•¿åº¦æ˜¯å˜åŒ–çš„ï¼Œå› æ­¤æˆ‘ä»¬åœ¨é¢å¯¹è¿™ç§ä»»åŠ¡çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥å€ŸåŠ©**self-attention**å±‚ã€‚\n\n## Detail\n\n![Pasted image 20230315195603](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315195603.png)\n\nå¯¹äºSelf-attentionå±‚ï¼Œç”Ÿæˆçš„$b^i$å‘é‡æ˜¯è€ƒè™‘åˆ°æ‰€æœ‰è¾“å…¥$\\sum_i\\alpha^i$å‘é‡\n\n### Vector Relevance\n\n![250](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315200009.png)\n\n\n* *Step 1.* ä½¿ç”¨Dot-product å»è®¡ç®— vector relevance\n\n![400](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315201906.png)\n\n* *Step 2.* Normalizingè®¡ç®—å‡ºæ¥çš„vector relevance\n![400](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315202047.png)\n\n* *Step 3.*  æ ¹æ®vector relevanceï¼Œä¹Ÿå°±æ˜¯attention scoresè®¡ç®—æœ€åçš„è¾“å‡ºã€‚è¿™æ˜¯ä¸€ä¸ªReweighting Processï¼Œä¸€ä¸ªextract information based on attention scores\n\n![400](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315202314.png)\n\n\u003e [!hint] \n\u003e  ä»ä¸Šé¢çš„è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥çœ‹å‡ºï¼Œ$b^i$äº’ç›¸ä¹‹é—´çš„è®¡ç®—æ²¡æœ‰å…³ç³»ï¼Œå…·æœ‰å¾ˆå¥½çš„å¹¶è¡Œæ€§\n\n### Matrix Detail\n\n$$\nq^i = W^q \\alpha^i\n$$\n\n\n$$\nQ = [q^1 \\quad q^2 \\quad \\cdots \\quad q^N],\\ \\ Â I = [\\alpha^1 \\quad \\alpha^2 \\quad \\cdots \\quad \\alpha^N]\n$$\n\n\n\nSo,\n\n$$\nQ = W^q I\n$$\n\nAs same,\n$$\nK = W^k I,\\quad V = W^v I\n$$\nCalculate attention score $\\alpha$,\n$$\n\\begin{bmatrix}\n\\alpha_{1,1} \\\\\n\\alpha_{1,2} \\\\\n\\cdots \\\\\n\\alpha_{1,N}\n\\end{bmatrix} =\n\\begin{bmatrix}\nk^1 \\\\\nk^2 \\\\\n\\cdots \\\\\nk_N\n\\end{bmatrix} q^1\n$$\n\nSo,\n$$\nA=\\begin{bmatrix}\n\\alpha_{1,1} \u0026 \\alpha_{2,1} \u0026 \\cdots \u0026 \\alpha_{N,1} \\\\\n\\alpha_{1,2} \u0026 \\alpha_{2,2} \u0026 \\cdots \u0026 \\alpha_{N,2} \\\\\n\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots\\\\\n\\alpha_{1,N} \u0026 \\alpha_{2,N} \u0026 \\cdots \u0026 \\alpha_{N,N}\n\\end{bmatrix} =\n\\begin{bmatrix}\nk^1 \\\\\nk^2 \\\\\n\\cdots \\\\\nk_N\n\\end{bmatrix} [q^1 \\quad q^2 \\quad \\cdots \\quad q^N] = K^TQ\n$$\n\n$$\nA' = \\text{Softmax}(A)\n$$\n\nFinally, calculate output $b$\n\n$$\nO = [b^1 \\quad b^2 \\quad \\cdots \\quad b^N] = [v^1 \\quad v^2 \\quad \\cdots \\quad v^N] = VA'\n$$\n\n![600](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315205148.png)\n\n### Positional Encoding\n![250](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315205727.png)\n* Each position has a unique positional vector $e^i$\n\t* hand-crafted\n\t* learned from data\n\n## Fun Facts\n\n### Self-attention vs. CNN\n\n![Pasted image 20230315205918](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315205918.png)\n\nå› ä¸ºtransformeræœ‰ç€æ›´å¤§çš„function setï¼Œæ‰€ä»¥éœ€æ±‚æ›´å¤šçš„æ•°æ®; ![Pasted image 20230315210032](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315210032.png)\n\n### Self-attention vs. RNN\n\nç›®å‰ï¼ŒRNNçš„è§’è‰²æ­£åœ¨è¢«self-attentionæ›¿ä»£ï¼ŒRNNåœ¨long seqçš„æƒ…å†µä¸‹ï¼Œå‰é¢çš„ä¿¡æ¯ä¼šè¢«é€æ¸é—å¿˜ï¼›åŒæ—¶**RNNæ²¡æœ‰å¹¶è¡Œæ€§**\nåŒæ ·ï¼ŒSelf attentionæœ‰ç€æ¯”RNNæ›´å¤§çš„function setï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œself-attentionå¯ä»¥å˜æˆRNN\n\n# Multi-head Self-attention\nMulti-head self attentionå°±æ˜¯ç”±ä¸åŒçš„self attention layeråœ¨ä¸€èµ·ï¼Œæœ‰ä¸åŒçš„$W^q$,$W^k$æ¥è´Ÿè´£ä¸åŒç§ç±»çš„relevance\n\n![600](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315210631.png)\n![300](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230315210704.png) ","lastmodified":"2023-03-30T12:42:55.330554194Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep-Learning-Block/Deep-Learning-Block":{"title":"Deep Learning Block - MOC","content":"\n[[Deep Learning And Machine Learning/Deep Learning Block/â­Attention|Attention Blocker]]\n\n[[Deep Learning And Machine Learning/Deep Learning Block/Transformer|Transformer]]\n\n","lastmodified":"2023-03-30T12:42:55.278553332Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep-Learning-Block/Transformer":{"title":"Transformer","content":"\n\u003e [!info] \n\u003e åœ¨å­¦ä¹ Transformerå‰ï¼Œä½ éœ€è¦å­¦ä¹  [â­Attention](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/â­Attention.md)\n\n\n\nTransformer æ˜¯Seq2Seq modelï¼Œç”±Encoderå’ŒDecoderç»„æˆ\n![300](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230316160103.png)\n\n# Encoder\nè¿™é‡Œè´´çš„æ˜¯åŸæ–‡Encoderçš„æ¶æ„\n![Pasted image 20230316162635](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230316162635.png)\n\n![Pasted image 20230316162642](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/attachments/Pasted%20image%2020230316162642.png)","lastmodified":"2023-03-30T12:42:55.278553332Z","tags":null},"/Deep-Learning-And-Machine-Learning/Deep-_Learning_MOC":{"title":"Deep Learning - MOC","content":"\n* [Deep Learning Block](Deep%20Learning%20And%20Machine%20Learning/Deep%20Learning%20Block/Deep%20Learning%20Block.md)\n\n* [Model Interpretability](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/Model_Interpretability_MOC.md)\n\n","lastmodified":"2023-03-30T12:42:55.330554194Z","tags":null},"/Deep-Learning-And-Machine-Learning/Model_interpretability/Model_Interpretability_MOC":{"title":"Model Interpretability - MOC","content":"\n* [SHAP](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/SHAP.md)\n","lastmodified":"2023-03-30T12:42:55.330554194Z","tags":null},"/Deep-Learning-And-Machine-Learning/Model_interpretability/SHAP":{"title":"SHAP - a reliable way to analyze model interpretability","content":"\nSHAP is the most popular model-agnostic technique that is used to explain predictions. SHAP stands for **SH**apley **A**dditive ex**P**lanations\n\nShapely values are obtained by incorporating concepts fromÂ *Cooperative Game Theory*Â  andÂ *local explanations*\n\n# Mathematical and Algorithm Foundation\n\n## Shapely Values\n\nShapely values were from game theory and invented by Lloyd Shapley. Shapely values were invented to be a way of providing a fair solution to the following question:\n\n\u003e [!question] \n\u003e  If we have a coalition **C** that collaborates to produce a value **V**: How much did each individual member contribute to the final value\n\nThe method here we assess each individual memberâ€™s contribution is to removing each member to get a new coalition and then compare their production, like this graphs:\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165429.png)\n\nAnd then, we get every member 1 included or not included coalitions like this:\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165523.png)\n\nUsing left value - right value, we can get difference like image left above; And then we calculate the mean of them:\n\n$$\n\\varphi_i=\\frac{1}{\\text{Members}}\\sum_{\\forall \\text{C s.t. i}\\notin \\text{C}} \\frac{\\text{Marginal Contribution of i to C}}{\\text{Coalitions of size |C|}}\n$$\n\n## Shapely Additive Explanations\n\nWe need to know whatâ€™s **additive** mean here. Lundberg and Lee define an additive feature attribution as follows:\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165623.png)\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165818.png)\n\n$x'$, the simplified local inputs usually means that we turn a feature vector into a discrete binary vector, where features are either included or excluded. Also, the $g(x')$ should take this form:\n\n$$\ng(x')=\\varphi_0+\\sum_{i=1}^N \\varphi_i {x'}_i\n$$\n\n* $\\varphi_0$ is the **null output** of this model, that is, the **average output** of this model\n-  $\\varphi_i$ is **feature affect**, is how much that feature changes the output of the model, introduced above. Itâ€™s called **attribution**\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329165840.png)\n\nNow Lundberg and Lee go on to describe a set of three desirable properties of such an additive feature method, **local accuracy**, **missingness**, and **consistency**.\n\n### Local accuracy\n\n$$\ng(x')\\approx f(x) \\quad \\text{if} \\quad x'\\approx x\n$$\n\n### Missingness\n\n$$\n{x_i}' = 0 \\rightarrow \\varphi_i = 0\n$$\n\nif a feature excluded from the model. itâ€™s attribution must be zero; that is, the only thing that can affect the output of the explanation model is the inclusion of features, not the exclusion.\n\n### Consistency\n\nIf feature contribution changes, the feature effect cannot change in the opposite direction\n\n# Why SHAP\n\nLee and Lundberg in their paper argue that only SHAP satisfies all three properties if **the feature attributions in only additive explanatory model are specifically chosen to be the shapley values of those features**\n\n# SHAP, step-by-step Process, same as shap.explainer\n\nFor example, we consider a ice cream shop in the airport, it has four features we can know to predict his business.\n\n$$\n\\begin{bmatrix}\n\\text{temperature} \u0026 \\text{day of weeks} \u0026 \\text{num of flights} \u0026 \\text{num of hours}\n\\end{bmatrix}\n\\\\\n\\rightarrow \\\\\n\\begin{bmatrix}\nT \u0026 D \u0026 F \u0026 H\n\\end{bmatrix}\n$$\n\nFor, example, we want to know the temperature 80 in sample [80 1 100 4] shapley value, hereâ€™s the step\n\n- Step 1. Get random permutation of features, and give a bracket to the feature we care and everything in its right. (manually)\n\n$$\n\\begin{bmatrix}\nF \u0026 D \u0026 \\underbrace{T \\quad H}\n\\end{bmatrix}\n$$\n\n- Step 2. Pick random sample from dataset\n \nFor example, [200 5 70 8], form: [F D T H]\n\n- Step 3. Form vectors $x_1 \\quad x_2$\n\n$$\nx_1=[100 \\quad 1 \\quad 80 \\quad \\color{#BF40BF} 8 \\color{#FFFFFF}] \n$$\n\n$x_1$ is partially from original sample and partially from the random chosen one, the feature in bracket will from random chosen one, exclude what we care\n\n$$\nx_2 = [100 \\quad 1 \\quad \\color{#BF40BF} 70 \\quad  8 \\color{#FFFFFF}]\n$$\n\n$x_2$  just change the feature we care into the same as random chosen oneâ€™s feature value\n\nThen, calculate the diff and record\n\n$$\nDIFF = c_1 - c_2\n$$\n\n- Step 4. Record the diff \u0026 return to step 1. and repeat many times\n\n$$\n\\text{SHAP}(T=80 | [80 \\quad 1 \\quad 100 \\quad 4]) = \\text{average(DIFF)}\n$$\n\n# Shapley kernel\n\n## Too many coalitions need to be sampled\n\nLike we introduce shapley values above, for each $\\varphi_i$ we need to sample a lot of coalitions to compute the difference. \n\nFor 4 features, we need 64 total coalitions to sample; For 32 features, we need 17.1 billion coalitions to sample.\n\nItâ€™s entirely untenable.\n\nSo, to get over this difficulty, we need devise a **shapley kernel**, and thatâ€™s how the Lee and Lundberg do\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329181956.png)\n\n## Detail\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329182011.png)\n\nThough most of ML models wonâ€™t just let you omit a feature, what we do is define a **background dataset** B, one that contains a set of representative data points that model was trained over. We then filled in out omitted feature of features with values from background dataset, while holding the features are included in the permutation fixed to their original values. We then take the average of the model output over all of these new synthetic data point as our model output for that feature permutation which we call $\\bar{y}$.\n\n$$\nE[y_{\\text{12i4}}\\ \\  \\forall \\ \\text{i}\\in B] = \\bar{y}_{\\text{124}}\n$$ \n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329205039.png)\n\nThem we have a number of samples computed in this way,like image in left.\n\nWe can formulate this as a weighted linear regression, with each feature assigned a coefficient.\n\nAnd we can prove that, in the special choice, the coefficient can be the shaplely values. **This weighting scheme is the basis of the Shapley Kernal.** In this situation, the weighted linear regression process as a whole is Kernal SHAP.\n\n### Different types of SHAP\n\n- **Kernal SHAP**\n- Low-order SHAP\n- Linear SHAP\n- Max SHAP\n- Deep SHAP\n- Tree SHAP\n\n![](Deep%20Learning%20And%20Machine%20Learning/Model_interpretability/attachments/Pasted%20image%2020230329205130.png)\n\n### You need to notice\nWe can see that, we calculate shapley values using linear regression lastly. So there must be the error here, but some python packages can not give us the error bound, so itâ€™s confusion to konw if this error come from linear regression or the data, or the model.\n\n\n# Reference\n\n[Shapley Additive Explanations (SHAP)](https://www.youtube.com/watch?v=VB9uV-x0gtg)\n\n[SHAP: A reliable way to analyze your model interpretability](https://towardsdatascience.com/shap-a-reliable-way-to-analyze-your-model-interpretability-874294d30af6)\n\n[ã€Pythonå¯è§£é‡Šæœºå™¨å­¦ä¹ åº“SHAPã€‘ï¼šPythonçš„å¯è§£é‡Šæœºå™¨å­¦ä¹ åº“SHAP](https://zhuanlan.zhihu.com/p/483622352)\n\n[Shapley Values : Data Science Concepts](https://www.youtube.com/watch?v=NBg7YirBTN8)\n\n# Appendix\n\nOther methods to interprete model:\n\n[Papers with Code - SHAP Explained](https://paperswithcode.com/method/shap)","lastmodified":"2023-03-30T12:42:55.330554194Z","tags":null},"/Hardware/Hardware_MOC":{"title":"Hardware - MOC","content":"\n# Microcontroller unit (MCU)\n\n## Basic concepts\n\n* [Different programming interfaces](Hardware/MCU/Different%20programming%20interfaces.md)\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Hardware/MCU/Different-programming-interfaces":{"title":"Different programming interfaces","content":"# What is programming interfaces in MCU\n\nAÂ **programming interface**Â is a device that allows a programmer to connect to a microcontroller (MCU) and program it. The programming interface is used to load the program into the MCUâ€™s memory and debug it.\n\n# Different types of programming interfaces in MCU\nChipmakers have different names for programming interfaces that all basically do the same thing:\n-   ISP - programming interface for Atmel (now Microchip) AVRs. SPI-like (MISO, MOSI, SCK, reset). It can be used for flash programming and debugging.\n-   PDI - newer programming interface for Atmel AVRs (eg. Xmega). Uses two wires (data and clock). Can do the same as ISP.\n-   DebugWire - yet another interface from Atmel (this one uses only a single wire)\n-   ICSP - programming interface for Microchip PIC line of MCUs\n-   SWD - Serial Wire Debug - programming interface for MCUs with ARM Cortex-M cores (uses two wires - data and clock)\n-   JTAG - very generic term, SPI-like interface used forÂ [boundary scan](https://en.wikipedia.org/wiki/Boundary_scan), can also be used for programming/debugging MCUs (almost every vendor has its own protocol, so Cortex-M JTAG is not the same as AVR JTAG or Blackfin JTAG)\n-   Spy-Bi-Wire - yet another two wire programming interface, this one is for TI's MSP430 MCUs\n\n## SWD å’Œ JTAGçš„åŒºåˆ«\n\nç›®å‰åœ¨ä½¿ç”¨çš„st linkå¯ä»¥ä½¿ç”¨SWDå’ŒJTAGè¿™ä¸¤ç§debuggerå»è°ƒè¯•stm32ï¼Œæ‰€ä»¥è¿™ä¸¤ç§æ–¹å¼çš„åŒºåˆ«ä»¤äººæ¯”è¾ƒåœ¨æ„ï¼›\n* JTAGï¼ˆJoint Test Action Groupï¼Œè”åˆæµ‹è¯•è¡ŒåŠ¨å°ç»„ï¼‰æ˜¯ä¸€ç§å›½é™…æ ‡å‡†æµ‹è¯•åè®®ï¼Œä¸»è¦ç”¨äºèŠ¯ç‰‡å†…éƒ¨æµ‹è¯•ã€‚ç°åœ¨å¤šæ•°çš„é«˜çº§å™¨ä»¶éƒ½æ”¯æŒJTAGåè®®ï¼Œå¦‚ARMã€DSPã€FPGAå™¨ä»¶ç­‰ã€‚JTAGè°ƒè¯•æ¥å£å¿…é¡»ä½¿ç”¨VCCã€GNDç”µæºä¿¡å·ï¼Œä»¥åŠTMSã€TCKã€TDIã€TDOå››æ ¹è°ƒè¯•ä¿¡å·ï¼Œå¯é€‰TRSTã€RESETå¤ä½ä¿¡å·å’ŒRTCKï¼ˆåŒæ­¥æ—¶é’Ÿï¼‰ä¿¡å·ã€‚\n\t* TMS(Test Mode Select)ï¼šæ¨¡å¼é€‰æ‹©ï¼ŒTMSç”¨æ¥è®¾ç½®JTAGæ¥å£å¤„äºæŸç§ç‰¹å®šçš„æµ‹è¯•æ¨¡å¼ï¼›\n\t* TCK(Test Clock)ï¼šæ—¶é’Ÿè¾“å…¥ï¼›\n\t* TDI(Test Data Input)ï¼šæ•°æ®è¾“å…¥ï¼Œæ•°æ®é€šè¿‡TDIå¼•è„šè¾“å…¥JTAGæ¥å£ï¼›\n\t* TDO(Test Data Output)ï¼šæ•°æ®è¾“å‡ºï¼Œæ•°æ®é€šè¿‡TDOå¼•è„šä»JTAGæ¥å£è¾“å‡ºï¼›\n* ä¸²è¡Œè°ƒè¯•ï¼ˆSerial Wire Debugï¼‰ï¼Œæ˜¯ä¸€ç§å’ŒJTAGä¸åŒçš„è°ƒè¯•æ¨¡å¼ï¼Œä½¿ç”¨çš„è°ƒè¯•åè®®ä¹Ÿä¸ä¸€æ ·ï¼Œæ‰€ä»¥æœ€ç›´æ¥çš„ä½“ç°åœ¨è°ƒè¯•æ¥å£ä¸Šï¼Œä¸JTAGçš„20ä¸ªå¼•è„šç›¸æ¯”ï¼ŒSWDåªéœ€è¦4ä¸ªï¼ˆæˆ–è€…5ä¸ªï¼‰å¼•è„šï¼Œç»“æ„ç®€å•ï¼Œä½†æ˜¯ä½¿ç”¨èŒƒå›´æ²¡æœ‰JTAGå¹¿æ³›ï¼Œä¸»æµè°ƒè¯•å™¨ä¸Šä¹Ÿæ˜¯åæ¥æ‰åŠ çš„SWDè°ƒè¯•æ¨¡å¼ã€‚\n\t* SWDIOï¼šä¸²è¡Œæ•°æ®è¾“å…¥è¾“å‡ºï¼Œä½œä¸ºä»¿çœŸä¿¡å·çš„åŒå‘æ•°æ®ä¿¡å·çº¿ï¼Œå»ºè®®ä¸Šæ‹‰ï¼›\n\t* SWCLKï¼šä¸²è¡Œæ—¶é’Ÿè¾“å…¥ï¼Œä½œä¸ºä»¿çœŸä¿¡å·çš„æ—¶é’Ÿä¿¡å·çº¿ï¼Œå»ºè®®ä¸‹æ‹‰ï¼›\n\t* SWOï¼šä¸²è¡Œæ•°æ®è¾“å‡ºå¼•è„šï¼ŒCPUè°ƒè¯•æ¥å£å¯é€šè¿‡SWOå¼•è„šè¾“å‡ºä¸€äº›è°ƒè¯•ä¿¡æ¯ã€‚è¯¥å¼•è„šæ˜¯å¯é€‰çš„ï¼›\n\t* RESETï¼šä»¿çœŸå™¨è¾“å‡ºè‡³ç›®æ ‡CPUçš„ç³»ç»Ÿå¤ä½ä¿¡å·ï¼Œè¯¥å¼•è„šä¹Ÿä¸ºå¯é€‰\n\n* SWDæ¨¡å¼æ¯”JTAGåœ¨é«˜é€Ÿæ¨¡å¼ä¸‹é¢æ›´åŠ å¯é ã€‚åœ¨å¤§æ•°æ®é‡çš„æƒ…å†µä¸‹é¢JTAGä¸‹è½½ç¨‹åºä¼šå¤±è´¥ï¼Œä½†æ˜¯SWDå‘ç”Ÿçš„å‡ ç‡ä¼šå°å¾ˆå¤šã€‚*åŸºæœ¬ä½¿ç”¨JTAGä»¿çœŸæ¨¡å¼çš„æƒ…å†µä¸‹æ˜¯å¯ä»¥ç›´æ¥ä½¿ç”¨SWDæ¨¡å¼çš„ï¼Œåªè¦ä½ çš„ä»¿çœŸå™¨æ”¯æŒã€‚*\n* åœ¨GPIOåˆšå¥½ç¼ºä¸€ä¸ªçš„æ—¶å€™ï¼Œå¯ä»¥ä½¿ç”¨SWDä»¿çœŸï¼Œè¿™ç§æ¨¡å¼æ”¯æŒæ›´å°‘çš„å¼•è„šã€‚\n\n\n* åŒæ—¶JTAGè°ƒè¯•ç‰ˆæœ¬ä¸åŒçš„æƒ…å†µä¸‹ï¼š\n\t* JTAGV6 éœ€è¦çš„ç¡¬ä»¶æ¥å£ä¸º: GND, RST, SWDIO, SWDCLKï¼›\n\t* JTAGV7 éœ€è¦çš„ç¡¬ä»¶æ¥å£ä¸º: GND, RST, SWDIO, SWDCLKï¼Œç›¸å¯¹V6ï¼Œ å…¶é€Ÿåº¦æœ‰äº†æ˜æ˜¾çš„æé«˜ï¼Œé€Ÿåº¦æ˜¯ JTAGV6 çš„ 6 å€ã€‚ \n\t* JTAGV8 éœ€è¦çš„ç¡¬ä»¶æ¥å£ä¸º: VCC, GND, RST, SWDIO, SWDCLKï¼Œé€Ÿåº¦å¯ä»¥åˆ° 10Mã€‚\n\n\n\n# Reference\n\n[JTAG, SWD, EDBG, ICSP, ISP terms - Electrical Engineering Stack Exchange](https://electronics.stackexchange.com/questions/412029/jtag-swd-edbg-icsp-isp-terms)\n\n[jtagå’Œswdçš„åŒºåˆ«_jtagå’ŒswdåŒºåˆ«_è€¶ç¨£èµæˆ‘èŒçš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/yym6789/article/details/88721409)\n\n[STM32çš„JTAGå’ŒSWDæ¨¡å¼_å­¦æœ¯é©¬çš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/w1050321758/article/details/108663603)\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Cameras_Research/Polaroid/Polaroid":{"title":"Polaroid","content":"\n# Polaroid Background\n\n![](Photography/Cameras_Research/Polaroid/attachments/Pasted%20image%2020230330195031.png)\n\nPolaroidæ˜¯ä¸€å®¶æˆç«‹äº1937å¹´çš„ç¾å›½ç›¸æœºåŠç…§ç‰‡åˆ¶é€ å…¬å¸ï¼Œè¯¥å…¬å¸æ›¾ç»æ˜¯å³æ—¶ç›¸æœºå¸‚åœºçš„é¢†å¯¼è€…ã€‚Polaroidå…¬å¸åœ¨20ä¸–çºª50å¹´ä»£æ¨å‡ºäº†ç¬¬ä¸€å°å³æ—¶ç›¸æœºï¼Œå¹¶åœ¨éšåçš„å‡ åå¹´é‡Œä¸æ–­æ¨å‡ºå„ç§å‹å·çš„å³æ—¶ç›¸æœºå’Œèƒ¶ç‰‡ï¼Œæˆä¸ºäº†å…¨çƒå¹¿æ³›ä½¿ç”¨çš„å“ç‰Œã€‚\n\nPolaroidæœ€è‘—åçš„ç‰¹ç‚¹ä¹‹ä¸€æ˜¯å®ƒçš„â€œå³æ—¶å½±åƒâ€æŠ€æœ¯ï¼Œè¿™ç§æŠ€æœ¯å¯ä»¥ä½¿ç”¨æˆ·åœ¨æ‹æ‘„åå‡ ç§’é’Ÿå†…çœ‹åˆ°ä»–ä»¬æ‰€æ‹æ‘„çš„ç…§ç‰‡ã€‚Polaroidçš„å³æ—¶ç›¸æœºæˆä¸ºäº†è®¸å¤šäººè®°å½•é‡è¦æ—¶åˆ»å’Œåˆ›é€ ç‹¬ç‰¹è‰ºæœ¯ä½œå“çš„é€‰æ‹©ã€‚\n\né™¤äº†å³æ—¶ç›¸æœºï¼ŒPolaroidè¿˜ç”Ÿäº§å’Œé”€å”®å…¶ä»–ç›¸æœºã€ç›¸æœºé™„ä»¶ã€æ•°ç ç›¸æ¡†å’Œç…§ç‰‡æ‰“å°æœºç­‰äº§å“ã€‚æ­¤å¤–ï¼ŒPolaroidè¿˜ä¸å…¶ä»–å“ç‰Œåˆä½œï¼Œæ¨å‡ºäº†è®¸å¤šè”åæ¬¾å¼çš„ç›¸æœºå’Œå…¶ä»–äº§å“ã€‚\n\nåœ¨Polaroidæˆç«‹è¿‘90å¹´çš„å†å²ä¸­ï¼Œå®ƒçš„ç›¸æœºå’Œèƒ¶ç‰‡å·²ç»æˆä¸ºäº†æ–‡åŒ–å’Œè‰ºæœ¯çš„è±¡å¾ï¼Œå¹¶ç»§ç»­å½±å“ç€äººä»¬å¯¹æ‘„å½±å’Œå½±åƒåˆ›ä½œçš„è®¤çŸ¥ã€‚\n\n# Polaroid Camera Review\n\n* [Polaroid one600](Photography/Cameras_Research/Polaroid/Polaroid_one600.md)\n* [Polaroid Integral 600 Series](Photography/Cameras_Research/Polaroid/Polaroid_600.md)\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Cameras_Research/Polaroid/Polaroid_600":{"title":"Polaroid 600","content":"\n# Reference\n\n* [How do I use my Vintage Polaroid 600 camera? â€“ Retrospekt](https://retrospekt.com/blogs/ask-the-expert/how-do-i-use-my-vintage-polaroid-600-instant-camera)\n* [Polaroid Integral 600 Series - Camera-wiki.org - The free camera encyclopedia](http://camera-wiki.org/wiki/Polaroid_Integral_600_Series)\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Cameras_Research/Polaroid/Polaroid_one600":{"title":"Polaroid_one600","content":"\n\n![](Photography/Cameras_Research/Polaroid/attachments/Pasted%20image%2020230330195707.png)\n\n# Specifications\n\n- **(Wide) 100mm lens with minimum focus distance of 3 feet.**\n- **Maximum Aperture F12.9 (Don't know if it can change)**\n- **1/200 s to 1/3 s**\n- **Fixed focus.**\n- Exposure modes - **Program automatic**\n- \"Aerodynamic\" styling (particularly when folded) with downward curve at back.\n- Flash moved to right hand side of user and can be manually switched on and off.\n- Hand grip on right.\n- LCD frame counter.\n- Self-timer.\n\n## Functionally similar models\n\n-   Polaroid One (silver/grey)\n-   Polaroid One600 Job Pro (black/silver/yellow) (Close-focus to 18 inches!)\n-   Polaroid One600 Nero (all black)\n-   Polaroid One600 \"Flowers\" (white with purple and yellow flower design)\n-   Polaroid One600 Panna (white/black)\n-   Polaroid One600 \"Poison Frog\" (silver/grey with yellow/black pattern)\n-   Polaroid One600 Polala 2006 (red/silver with gold Chinese dragon)\n-   Polaroid One600 Pro (all silver) (Like Job Pro, close-focus to 18 inches!)\n-   Polaroid One600 Royksopp (grey/silver with 'Royksopp - Only This Moment' branding)\n-   Polaroid One600 Superheadz Special Edition Red Hat (silver/black, with 'red hat' cartoon character)\n-   Polaroid One600 Rossa (bright red/black)\n-   Polaroid One Rossa (as above)\n-   Polaroid One Ultra (silver/black) (Close focus to 2 feet)\n-   Polaroid Pop Kit (silver/black with stickers for user's customization)\n\n# Reference\n\n* [Polaroid One 600 Camera Review - by Dan Finnen](https://danfinnen.com/review/polaroid-one-600-camera-review/)\n* [Polaroid One600 (Classic) - Camera-wiki.org - The free camera encyclopedia](http://camera-wiki.org/wiki/Polaroid_One600_(Classic))\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Photography_MOC":{"title":"Photography - MOC","content":"\n# ğŸŒŠPhoto Portfolio\nYou can see my photography works in:\n\n* [ğŸ¨Slide show](https://pinkr1ver.com/PhotoGallery/)\n* [ğŸŒ„Photo Collection in Notion](https://www.notion.so/pinkr1ver/3cfdd332b9a94b20bca041f2aa2bdcd2?v=24e696e6ab754386a710bc8e83976357)\n* [ğŸ»Instagram](https://www.instagram.com/jude.wang.yc/?next=%2F)\n* [ğŸ§¶å°çº¢ä¹¦](https://www.xiaohongshu.com/user/profile/6272c025000000002102353b)\n\n# Notes\nAlso, here's my notes about learning photography\n\n## About Basic Concepts:\n\n* [Saturation](Photography/Saturation.md)\n\n## Appreciation of other works - about ***aesthetic***\n\n* [ğŸ¦ºæ¬è¿UPä¸» - è±†è…ç´ åŒ…](https://space.bilibili.com/196700312/video)\n* [ğŸ‘§Portrait](Photography/Portrait.md)\n\n## Camera Research\n\n* [âœ¨Polaroid](Photography/Cameras_Research/Polaroid/Polaroid.md)\n\n# Reference\n\n## Platform\n\n* [Magnum Photos](https://www.magnumphotos.com/)\n* [CNU - Catch Next Ultimate](http://www.cnu.cc/)\n\n## Greatest Artist\n\n* [linksphotograph](https://www.linksphotograph.com/)\n* [HAMADA Hideaki / æ¿±ç”°è‹±æ˜](https://www.hideakihamada.com)\n* [Jason Kummerfeldt](https://graincheck.darkroom.com/) and [his youtube](https://www.youtube.com/@grainydaysss)\n* [Marta Bevacqua](https://www.martabevacquaphotography.com/)\n* [Sam Zhang](https://www.instagram.com/itscapturedbysam/)","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Portrait":{"title":"ğŸ‘§Portrait","content":"\n* [ğŸŒ¸Flower \u0026 Girl](Photography/Portrait/Flower_and_Girl.md)\n* [ğŸ‡°ğŸ‡·Cute Portrait from Korean MV \u003cToday's Mood\u003e](Photography/Portrait/From%20Korean%20MV%20Todays_Mod.md)\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Portrait/Flower_and_Girl":{"title":"ğŸŒ¸Flower \u0026 Girl","content":"\nCredits to [Marta Bevacqua](https://www.martabevacquaphotography.com/), \nThanksğŸŒ¸\n\n![](Photography/Portrait/attachments/14.jpg)\n\n![](Photography/Portrait/attachments/15.jpg)\n\n![](Photography/Portrait/attachments/16.jpg)\n\n![](Photography/Portrait/attachments/17.jpg)\n\n![](Photography/Portrait/attachments/18.jpg)\n\n![](Photography/Portrait/attachments/19.jpg)\n\n![](Photography/Portrait/attachments/20.jpg)\n\n![](Photography/Portrait/attachments/21.jpg)\n\n![](Photography/Portrait/attachments/22.jpg)\n\n![](Photography/Portrait/attachments/content%20(1).jpg)\n\n![](Photography/Portrait/attachments/content%20(2).jpg)\n\n![](Photography/Portrait/attachments/content%20(3).jpg)\n\n![](Photography/Portrait/attachments/content%20(4).jpg)\n\n![](Photography/Portrait/attachments/content%20(5).jpg)\n\n![](Photography/Portrait/attachments/content%20(6).jpg)\n\n![](Photography/Portrait/attachments/content%20(7).jpg)\n\n![](Photography/Portrait/attachments/content%20(8).jpg)\n\n![](Photography/Portrait/attachments/content%20(9).jpg)\n\n![](Photography/Portrait/attachments/content%20(11).jpg)\n\n![](Photography/Portrait/attachments/content%20(12).jpg)\n\n![](Photography/Portrait/attachments/content.jpg)\n\n","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Portrait/From-Korean-MV-Todays_Mod":{"title":"Cute Portrait from Korean MV \u003cToday's Mood\u003e","content":"\nCredits to [MV - CHEEZE(ì¹˜ì¦ˆ) _ Today's Mood(ì˜¤ëŠ˜ì˜ ê¸°ë¶„)](https://www.youtube.com/watch?v=zRq_DlEzygk),\nThanks\n\nAlso, I see this in [æ‘„å½±çµæ„Ÿï½œé‚£æœ‰ä¸€ç‚¹å¯çˆ± - by   \nå°å…«æ€ª](https://www.xiaohongshu.com/explore/63f0a27e0000000013002b05)\n\n![](Photography/Portrait/attachments/photo_4_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_5_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_6_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_7_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_8_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_9_2023-03-27_23-53-20.jpg)\n\n![](Photography/Portrait/attachments/photo_1_2023-03-27_23-53-20%201.jpg)\n\n![](Photography/Portrait/attachments/photo_2_2023-03-27_23-53-20%201.jpg)\n\n![](Photography/Portrait/attachments/photo_3_2023-03-27_23-53-20%201.jpg)\n\n![](Photography/Portrait/attachments/photo_2023-03-27_23-55-45.jpg)","lastmodified":"2023-03-30T12:42:55.342554393Z","tags":null},"/Photography/Saturation":{"title":"Saturation - é¥±å’Œåº¦","content":"\nto be written...","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Signal-Processing/Basic-Concepts-in-Signal-Processing":{"title":"Basic Concepts in Signal Processing","content":"\n* [What is dB](Signal%20Processing/What%20is%20dB.md)","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Signal-Processing/Signal-Processing_MOC":{"title":"Signal Processing - MOC","content":"\n* [Basic Concepts in Signal Processing](Signal%20Processing/Basic%20Concepts%20in%20Signal%20Processing.md)\n","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Signal-Processing/What-is-dB":{"title":"What is dB","content":"dB is short for decibel, which is a unit that indicates ratio or gain.Â It is often used to measure *sound intensity*, *signal strength*, *attenuation* and other quantities. \n\nFor example, if a sound has a power of 10 W and another sound has a power of 1 W, then the difference in decibels is 10 dB = 10 log (10/1) = 10 log 10 = 10.\n\n**Signal Noise Ratio** is also measured by dB\n\n## Signal Noise Ratio\n$$\n{SNR}_{power}=\\frac{\\text{Average Signal Power}}{\\text{Average Noise Power}}\n$$\n\n$$\n{SNR}_{voltage}=\\frac{\\text{RMS Signal Voltage}}{\\text{RMS Noise Voltage}}\n$$\n\n$$\n{SNR}_{power}={{SNR}_{voltage}}^2\n$$\n\n$$\n{SNR}_{dB}=10\\log_{10}{{SNR}_{power}}=20\\log_{10}{{SNR}_{voltage}}\n$$\n","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/Antenna":{"title":"Antenna","content":"\n# Theorem\n\n## è°æŒ¯ç”µè·¯ (Resonant circuit) - RLC for example\n\n### ä»€ä¹ˆæ˜¯è°æŒ¯\n\nç”µè·¯ä¸­ç”µå®¹å™¨$L$ã€ç”µæ„Ÿå™¨$C$ä¸¤ç»„ä»¶ä¹‹èƒ½é‡ç›¸ç­‰ï¼Œå½“èƒ½é‡ç”±ç”µè·¯ä¸­æŸä¸€ç”µæŠ—ç»„ä»¶é‡Šå‡ºæ—¶ï¼Œä¸”å¦ä¸€ç”µæŠ—ç»„ä»¶å¿…å¸æ”¶ç›¸åŒä¹‹èƒ½é‡ï¼Œå³æ­¤ä¸¤ç”µæŠ—ç»„ä»¶é—´ä¼šäº§ç”Ÿä¸€èƒ½é‡è„‰åŠ¨ã€‚\n\n### ä¸¤ç§ç®€å•çš„è°æŒ¯ç”µè·¯\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230330160535.png)\n\n\n#### *Resonant Frequency*\n\nç”µå®¹ï¼Œç”µé˜»çš„[ç”µæŠ—](Circuit/Basic/Electric_units.md#Electrical%20impedance)ç›¸åŒæ—¶å‘ç”Ÿè°æŒ¯\n\n$$\n|X_C| = |\\frac{1}{j2\\pi fC}| = |X_L| = |j2\\pi fL|\n$$\nRearranging,\n\n$$\nf^2 =  \\frac{1}{(2\\pi)^2 C L}\n$$\n\n$$\nf = \\frac{1}{2\\pi \\sqrt{LC}}\n$$\n\n","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/Electromagnetic_Theory":{"title":"Electromagnetic Theory","content":"\n","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/Radiometric-Calibration":{"title":"Radiometric Calibration - è¾å°„æ ¡å‡†","content":"\n# Overview\nSAR æ ¡å‡†æ—¨åœ¨æä¾›å…¶åƒç´ å€¼å¯ä¸åœºæ™¯ä¸­çš„é›·è¾¾åå‘æ•£å°„ç›´æ¥ç›¸å…³çš„å½±åƒã€‚è™½ç„¶æœªæ ¡å‡†çš„ SAR å½±åƒè¶³ä»¥ç”¨äºå®šæ€§ç”¨é€”ï¼Œä½†æ ¡å‡†åçš„ SAR å½±åƒå¯¹äºå®šé‡ä½¿ç”¨ SAR æ•°æ®è€Œè¨€ä»è‡³å…³é‡è¦ã€‚\n\nç”Ÿæˆçº§åˆ« 1 å½±åƒçš„å…¸å‹ SAR æ•°æ®å¤„ç†ä¸åŒ…æ‹¬è¾å°„æ ¡æ­£ï¼Œä¸”ä»ç„¶å­˜åœ¨æ˜æ˜¾çš„è¾å°„åå·®ã€‚å› æ­¤æœ‰å¿…è¦å¯¹ SAR å½±åƒåº”ç”¨è¾å°„æ ¡æ­£ï¼Œ*ä½¿å½±åƒçš„åƒç´ å€¼çœŸæ­£èƒ½å¤Ÿåæ˜ åå°„è¡¨é¢çš„é›·è¾¾åå‘æ•£å°„æƒ…å†µ*ã€‚åœ¨æ¯”è¾ƒç”±ä¸åŒçš„ä¼ æ„Ÿå™¨é‡‡é›†çš„ SAR å½±åƒæ—¶ï¼Œæˆ–æ¯”è¾ƒç”±åŒä¸€ä¼ æ„Ÿå™¨åœ¨ä¸åŒæ—¶é—´ã€ä¸åŒæ¨¡å¼ä¸‹é‡‡é›†çš„ï¼ˆæˆ–ç”±ä¸åŒå¤„ç†å™¨å¤„ç†çš„ï¼‰SAR å½±åƒæ—¶ï¼Œéƒ½éœ€è¦è¿›è¡Œè¾å°„æ ¡æ­£ã€‚\n\n## Types\n* **Sigma nought** - ç”¨äºæ ¡å‡†åœ°é¢ä¸Šå•ä½é¢ç§¯å†…è¿”å›åˆ°å¤©çº¿çš„åå‘æ•£å°„ï¼Œå¹¶ä¸åœ°é¢èŒƒå›´ç›¸å…³ã€‚å½±åƒç»è¿‡æ ¡å‡†ï¼Œå› æ­¤å¯ä»¥ç›´æ¥ä¸ç›¸åŒæˆ–ä¸åŒä¼ æ„Ÿå™¨æ”¶é›†çš„ä¸åŒé›·è¾¾å½±åƒè¿›è¡Œæ¯”è¾ƒã€‚ç§‘å­¦å®¶å€¾å‘äºä½¿ç”¨ sigma naught æ¥è§£é‡Šè¡¨é¢æ•£å°„ã€è¡¨é¢åå°„ä»¥åŠè¡¨é¢å±æ€§ã€‚\n\t* *Scattering coefficient*, or the conventional measure of the strength of radar signals reflected by a distributed scatterer, usually expressed in dB. It is a *normalised dimensionless number*, comparing the strength observed to that expected from an area of one square meter. Sigma nought is defined with respect to the nominally horizontal plane, and in general has a significant variation with **incidence angle**, **wavelength**, and **polarisation**, as well as with **properties of the scattering surface itself**.\n* **Beta nought** - å¯ç”ŸæˆåŒ…å«é›·è¾¾äº®åº¦ç³»æ•°çš„æ•°æ®é›†ï¼ˆé›·è¾¾äº®åº¦ç³»æ•°æ˜¯å¤©çº¿å‘å°„åŠŸç‡ä¸æ¥æ”¶åŠŸç‡ä¹‹æ¯”ï¼‰ã€‚å®ƒä¸å€¾æ–œèŒƒå›´æœ‰å…³ï¼Œä¸”æ— ç»´åº¦ã€‚\n* **Gamma**Â - é€šå¸¸åœ¨æ ¡å‡†å¤©çº¿æ—¶ä½¿ç”¨ã€‚å› ä¸ºæ¯ä¸ªèŒƒå›´åƒå…ƒä¸å«æ˜Ÿçš„è·ç¦»å‡ç›¸ç­‰ï¼Œæ‰€ä»¥è¿‘è·èŒƒå›´å’Œè¿œè·èŒƒå›´çš„äº®åº¦å‡ç›¸ç­‰ï¼Œè¿™æœ‰åŠ©äºç¡®å®šè¾“å‡ºæ•°æ®é›†ä¸­çš„å¤©çº¿æ–¹å‘å›¾ã€‚\n* **None** - ä¸åšæ ¡æ­£\n\n\n\n# Reference\n\n* [Sentinel-1 Radiometric Calibrationâ€”ArcMap | Documentation (arcgis.com)](https://desktop.arcgis.com/en/arcmap/latest/manage-data/raster-and-images/sentinel-1-radiometric-calibration.htm)\n\n* [Urban objects detection from C-band synthetic aperture radar (SAR) satellite images through simulating filter properties | Scientific Reports (nature.com)](https://www.nature.com/articles/s41598-021-85121-9)\n\n* [âœ¨âœ¨âœ¨User Guides - Sentinel-1 SAR - Definitions - Sentinel Online - Sentinel Online (esa.int)](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/definitions)\n\n","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/SAR-Explained":{"title":"Synthetic Aperture Radar (SAR) Explained","content":"\n# Radar Basic Concepts\n\n## Down Looking vs. Side Looking\n\n![Pasted image 20230320150424](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230320150424.png)\n\nDown Lookingä¸èƒ½åŒºåˆ†è·ç¦»ä¸€æ ·çš„aï¼Œbç‚¹ï¼Œä¸€èˆ¬åªç”¨äºmonitoring of air and naval traffic\n\n## Simplified explanation of Radar working \u0026 What is SAR\nThe radar consists fundamentally of *a transmitter*, *a receiver*, *an antenna* and *an electronic system* to process and record the data.\n\nThe transmitter generates successive short bursts or pulses of microwave at regular intervals which are focused by the antenna into a beam. Radar beam illuminates the surface **obliquely** at a right angle to the motion of the platform. The antenna receives a portion of the transmitted energy reflected or it's known as backscattered from various objects within the illuminated beam by  measuring this time delay between the transmission of a pulse and the reception of the backscattered echo from different  targets. Their distance from the radar and therefore their location can be determined as the sensor platform *moves forward* recording and processing of the backscattered signals builds up a 2-dimensional image of the surface.\n\n\n\u003e [!important] \n\u003e Important\u003cbr\u003e\n\u003e The along track **resolution** is determined by the beam width which is *inversely proportional to the antenna length*, also known as the **aperture**, which means that longer antenna or a longer aperture will produce a narrow beam and a finer resolution. \u003cbr\u003e\n\u003e Long antenna $\\leftrightarrow$ Small beam $\\leftrightarrow$ Long aperture $\\leftrightarrow$ Better image resolution\n\n### Detail geometry\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230330153450.png)\n**Fig** *Geometry of a side-looking real aperture radar. (SLAR)*\n\nside-lookingçš„é›·è¾¾è¢«åˆ†ä¸ºtwo types â€”â€” real aperture radar(*SLAR or SLR*, SL for side-looking)å’Œsynthetic aperture radar(SAR)\n\nå¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œé›·è¾¾å‘å‡ºçš„pulseè¢«[antennaèšç„¦](Synthetic%20Aperture%20Radar%20Imaging/Antenna.md)åœ¨ä¸€ä¸ªnarrowçš„areaé‡Œï¼Œç„¶åscatterååœ¨ä¸åŒå’Œçš„æ—¶é—´å†è¢«receiveræ¥æ”¶\n\n\n### Why SAR\nä»‹äºå®é™…æƒ…å†µä¸‹çš„ç‰©ç†ç©ºé—´ä¸­ï¼Œé›·è¾¾å¤©çº¿çš„å¤§å°æ˜¯é™çš„ï¼Œå¯ä»¥é€šè¿‡é›·è¾¾çš„ç§»åŠ¨å»æ¨¡æ‹Ÿé•¿å¤©çº¿æƒ…å†µä¸‹çš„é›·è¾¾ï¼Œä¹Ÿå°±æ˜¯æ´»å¾—æ›´å¤§çš„apertureï¼Œè¿™é¡¹è¢«å«åšSARã€‚ç›®çš„æ˜¯åœ¨äºä½¿ç”¨*comparatively small physical antennas*å»è·å¾—*high resolution images*\n\n\n## Review of Radar Image Formation\n\n![660](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230320163240.png)\n\n* Radar can measure *amplitude* and *phase*\n* Radar can only measure part of echoes.\n* The strength of the reflected echo is the backscattering coefficient ([sigma nought](Synthetic%20Aperture%20Radar%20Imaging/Radiometric%20Calibration.md)ï¼‰and is expressed in [decibels(dB)](Signal%20Processing/What%20is%20dB.md)\n\n## Radar Resolution\n\n\n\n## Radar Key Parameters\n* Wave Length\n* Polarization\n* Incidence Angle\n\n### Wave Length\n\n![](Synthetic%20Aperture%20Radar%20Imaging/attachments/Pasted%20image%2020230330153007.png)\n\né›·è¾¾æ•°æ®çš„ç©ºé—´åˆ†è¾¨ç‡ä¸ä¼ æ„Ÿå™¨æ³¢é•¿ä¸ä¼ æ„Ÿå™¨å¤©çº¿é•¿åº¦ä¹‹æ¯”ç›´æ¥ç›¸å…³ã€‚ å¯¹äºç»™å®šçš„æ³¢é•¿ï¼Œå¤©çº¿è¶Šé•¿ï¼Œç©ºé—´åˆ†è¾¨ç‡è¶Šé«˜ã€‚ å¯¹äºä»¥å¤§çº¦ 5 cm æ³¢é•¿è¿è¡Œçš„å¤ªç©ºå«æ˜Ÿï¼ˆC æ³¢æ®µé›·è¾¾ï¼‰ï¼Œä¸ºäº†è·å¾— 10 m çš„ç©ºé—´åˆ†è¾¨ç‡ï¼Œæ‚¨éœ€è¦ä¸€ä¸ªå¤§çº¦ 4,250 m é•¿çš„é›·è¾¾å¤©çº¿ã€‚ ï¼ˆè¶…è¿‡ 47 ä¸ªè¶³çƒåœºï¼ï¼‰\n\n\n# Reference\n\n* [Theory of Synthetic Aperture Radar (uzh.ch)](https://www.geo.uzh.ch/~fpaul/sar_theory.html)\n\n* ***Sentinel-1** is a famous SAR, you can find almost every *definitions* of SAR in this page:\n[User Guides - Sentinel-1 SAR - Definitions - Sentinel Online - Sentinel Online (esa.int)](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/definitions)\n\n* [SAR(Synthetic Aperture Radar)åŸºç¡€(ä¸€) - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/98053986)","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null},"/Synthetic-Aperture-Radar-Imaging/SAR_MOC":{"title":"Synthetic Aperture Radar (SAR) Imaging - MOC","content":"\n* [[Synthetic Aperture Radar Imaging/SAR Explained|SAR Explained]]\n","lastmodified":"2023-03-30T12:42:55.362554724Z","tags":null}}